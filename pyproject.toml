[tool.poetry]
name = "edge-llm-lab"
version = "0.1.0"
description = "Federated Learning Mobile Chat Application"
authors = ["Maria Jastrzebska <maria.jastrzebska@example.com>"]
packages = [
    { include = "edge_llm_lab", from = "src" }
]
package-mode = true

[tool.poetry.dependencies]
python = ">=3.10,<3.13" 
fastapi = "^0.109.2"
uvicorn = "^0.24.0"
pydantic = "^2.4.2"
flwr = "^1.5.0"
onnxruntime = ">=1.21.0"
transformers = "4.44.2"
numpy = "^1.24.0"
python-multipart = "^0.0.6"
python-jose = {extras = ["cryptography"], version = "^3.3.0"}
passlib = {extras = ["bcrypt"], version = "^1.7.4"}
ipykernel = "^6.0.0"
jupyter = "^1.0.0"
pydantic-settings = "^2.8.0"
starlette = "^0.36.3"
torch = "2.2.0"
huggingface_hub = "^0.26.0"
accelerate = "^0.31.0"
loguru = "^0.7.2"
boto3 = "^1.36.26"
mlflow = "^2.20.2"
onnx = "^1.16.0"
packaging = "^24.2"
colorama = "^0.4.6"
httpx = ">=0.27,<0.29"
openai = ">=1.52.0,<2.0.0"
instructor = "^1.7.2"
ollama = "^0.4.7"
aiohttp = "^3.11.13"
coremltools = "8.00"
cython = "0.29.33"
gguf = "^0.14.0"
nltk = "^3.9.1"
rouge-score = "^0.1.2"
scikit-learn = "^1.6.1"
sentence-transformers = "^4.1.0"
seaborn = "^0.13.2"
pandas = "^2.3.0"
pyyaml = "^6.0.2"
python-levenshtein = "^0.27.1"
llama-cpp-python = "^0.3.16"
optuna-integration = {extras = ["mlflow"], version = "^4.5.0"}


[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
pytest-asyncio = "^0.21.0"
black = "^23.9.1"
isort = "^5.12.0"
flake8 = "^6.1.0"
optimum = "^1.21.0"
pytest-watch = "^4.2.0"

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
download-models = "scripts.download_models:download_models"
